HPL DAT AND RUN SCRIPT


########################################################

########################
## HPL.DAT EXAMPLES
########################

## HPL DAT EXAMPLE (SINGLE NODE)

HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
10000        Ns
1            # of NBs
512          NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
1            Ps
1            Qs
16.0         threshold
1            # of panel fact
2            PFACTs (0=left, 1=Crout, 2=Right)
2            # of recursive stopping criterium
4 8          NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
2            RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
1            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
2            # of lookahead depth
0 1          DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64          swapping threshold (estaba en 128)
1            L1 in (0=transposed,1=no-transposed) form (CUDA obligatorio 1)
1            U  in (0=transposed,1=no-transposed) form (CUDA puede ser 1 o 0)
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)


######################################################################################

#################################
## RUN_LINPACK EXAMPLE FILES
#################################

## RUN_LINPACK (1 NODE)

#!/bin/bash

#location of HPL 
HPL_DIR=/home/nvidia/cloud/CUDAHPLBenchmark/hpl-2.0_FERMI_v15/

# Number of CPU cores ( per GPU used = per MPI process )
CPU_CORES_PER_GPU=1

# FOR MKL
export MKL_NUM_THREADS=$CPU_CORES_PER_GPU
# FOR GOTO
export GOTO_NUM_THREADS=$CPU_CORES_PER_GPU
# FOR OMP
export OMP_NUM_THREADS=$CPU_CORES_PER_GPU

export MKL_DYNAMIC=false

# hint: for 2050 or 2070 card
#       try 350/(350 + MKL_NUM_THREADS*4*cpu frequency in GHz) 
export CUDA_DGEMM_SPLIT=0.80

# hint: try CUDA_DGEMM_SPLIT - 0.10
export CUDA_DTRSM_SPLIT=0.70

export LD_LIBRARY_PATH=$HPL_DIR/src/cuda:$LD_LIBRARY_PATH

$HPL_DIR/bin/CUDA/xhpl


####################################

## 
##
